---
title: "Likelihood of helping and window time"
author: "Liza Moscovice, Anja Eggert and Jean-Loup Rault"
date: "`r Sys.Date()`" 
editor: visual
code-fold: false
toc: true
format: html
---

# Libraries

```{r, libraries, warning=FALSE, message=FALSE, echo=TRUE}
library(tidyverse)     # tidy universe
library(viridis)       # color scale
library(glmmTMB)       # neg. binomial model
library(performance)   # testZeroInflation()
library(DHARMa)        # model diagnostics
library(fastDummies)   # dummy-coding
```

```{r, my_theme, echo = FALSE}
my_theme = theme_classic() +
  theme(axis.title = element_text(face="bold", size=14),
        axis.text  = element_text(size=12, angle = 0, vjust = 0.5),
        plot.title = element_text(face="bold", size=14),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

```{r, seed}
set.seed(1989)
```

# Data

Likelihood of helping of the potential helper and the attentiveness to trapped pigs.

# Read data

```{r, data}
dat <- read_csv("../data/helping-window-time.csv")

str(dat)
```

# Zero-inflated negative binomial model

The zero-inflation model describes the probability of observing an extra (i.e., structural) zero that is not generated by the conditional model.

-   fit the model with zero-inflation is assumed to be constant across the data set (`ziformula = ~ 1`), *i.e.*, zero-inflation is independent of the predictor variables
-   chose `family = negbinom2`, *i.e.*, a negative binomial distribution in which the variance increases quadratically with the mean

## Run full model

```{r, model-contr}
contr = glmmTMBControl(optimizer = optim, optArgs = list(method="BFGS"))
```

```{r, model-full}
mod <- glmmTMB(pot.helper.response ~
                 # fixed, continuous predictors
                 as.vector(scale(test.dur.look.s.per.min))    +
                 as.vector(scale(sqrt(train.rate.open)))      +
                 as.vector(scale(sqrt(train.rate.curio.min))) +
                 as.vector(scale(group.trapped.pig.order))    +
                 # fixed, categorical predictors
                 pretrial.open.yn                    + 
                 pothelper.sex                       + 
                 related                             + 
                 # random effects
                 (1|pot.helper.uniq.id),
               # Negative binomial distribution
               family = "nbinom2",
               # expect zero-inflation equal in all obs
               ziformula = ~ 1,
               # data set
               data   = dat,
               # numerical optimizer
               control = contr)
```

## Run reduced model

```{r, model-reduced}
mod.red <- glmmTMB(pot.helper.response ~
                     # fixed, continuous predictors
                     as.vector(scale(sqrt(train.rate.curio.min))) +
                     as.vector(scale(group.trapped.pig.order))    +
                     # fixed, categorical predictors
                     pretrial.open.yn                    + 
                     pothelper.sex                       + 
                     related                             + 
                     # random effects
                     (1|pot.helper.uniq.id),
                   # Negative binomial distribution
                   family = "nbinom2",
                   # expect zero-inflation equal in all obs
                   ziformula = ~ 1,
                   # data set
                   data   = dat,
                   # numerical optimizer
                   control = contr)
```

## Model comparison

-   Likelihood ratio test compares goodness of fit of of the reduced and the full model, *i.e.*, determine whether or not adding complexity (adding more parameters) makes the full model significantly more accurate

```{r, model-comp}
anova(mod.red, mod, test='Chisq')
```

## Summary of model

```{r, model-summary}
summary(mod)
```

```{r, model-table}
car::Anova(mod)
```

## Performance of model

-   `performance` package used to check model assumptions

```{r, perf-1}
performance::check_collinearity(mod)
```

```{r, perf-2}
performance::check_overdispersion(mod)
```

-   `DHARMa` package used to test for zero-inflation, which compares the distribution of expected zeros from simulations against the observed zeros

```{r, perf-3}
DHARMa::testZeroInflation(mod)
```

# Plot

-   fit an additional **plot.model** with all predictors except the predictor of interest (`test.dur.look.s.per.min`) having a mean of zero

## Dummy-coding

-   using `fastDummies` to dummy-code categorical predictors, continuous predictors are z-transformed

```{r, dummy-code}
dat.dum <- fastDummies::dummy_cols(dat,
                                   select_columns = c(
                                     "pretrial.open.yn",
                                     "pothelper.sex",
                                     "related"),
                                   remove_first_dummy = TRUE) %>% 
  # categorical, dummy predictors
  mutate_at(vars(starts_with("pretrial.open.yn_")),
            ~(.)-mean(.)) %>%
  mutate_at(vars(starts_with("pothelper.sex_")), 
            ~(.)-mean(.)) %>%
  mutate_at(vars(starts_with("related_")),
            ~(.)-mean(.))
```

## Run plot model

```{r, data-conv}
# predictor of interest, now per minute
dat.dum <- dat.dum %>% 
  mutate(test.dur.look.s.per.min = test.dur.look.s.per.min/60)
```

```{r, plot-model}
plot.mod <- glmmTMB(pot.helper.response ~
                      # predictor of interest, now per minute
                      test.dur.look.s.per.min                     +
                      # scaled continuous predictors
                      as.vector(scale(sqrt(train.rate.open)))      +
                      as.vector(scale(sqrt(train.rate.curio.min))) +
                      as.vector(scale(group.trapped.pig.order))    +
                      # dummy-coded categorical predictors
                      pretrial.open.yn_Yes                    + 
                      pothelper.sex_Male                      + 
                      related_y                               + 
                      # random effects
                      (1|pot.helper.uniq.id),
                    # Negative binomial distribution
                    family = "nbinom2",
                    # expect zero-inflation equal in all obs
                    ziformula = ~ 1,
                    # data set
                    data   = dat.dum,
                    # numerical optimizer
                    control = contr)
```

## Extract fixed effects

-   create a vector spanning the range of `test.dur.look.s.per.min`
-   get fitted/estimated values for negative binomial part and zero-inflated part, with `fixef()`
-   as the fitted values are in the logit-link space, they need to be transformed into the space of the measurements

```{r, fixed-eff}
coeff.fixed <- fixef(plot.mod)

xvals <- seq(from       = min(dat.dum$test.dur.look.s.per.min),
             to         = max(dat.dum$test.dur.look.s.per.min),
             length.out = 100)

yvals.nb <- coeff.fixed$cond["(Intercept)"] +
  coeff.fixed$cond["test.dur.look.s.per.min"]*xvals
yvals.nb <- exp(yvals.nb)

yvals.zi <- coeff.fixed$zi["(Intercept)"]
yvals.zi <- exp(yvals.zi)/(1+exp(yvals.zi))

yvals <- (1-yvals.zi)*yvals.nb

plot.line <- tibble(xvals, yvals) %>% 
  filter(xvals <= 0.5)
```

## Plot it

-   group by `pot.helper.uniq.id` and calculate the mean of `pot.helper.response` (yes/no) and `test.dur.look.s.per.min` (numeric)

```{r, plot-1}
plot <- dat.dum %>% 
  group_by(pot.helper.uniq.id)%>%
  summarise(mean.look.min = mean(test.dur.look.s.per.min),
            mean.help     = mean(pot.helper.response),
            n_trials      = n()) %>% 
  ungroup() %>% 
  mutate(uniq.group = str_sub(pot.helper.uniq.id,1,5)) %>% 
  
  ggplot() +
  geom_jitter(aes(x    = mean.look.min, 
                  y    = mean.help, 
                  col  = as.factor(uniq.group),
                  size = n_trials),
              alpha = 0.7,
              na.rm = TRUE) + 
  scale_size(range = c(3, 4)) +
  scale_color_manual(values = viridis(n=8),
                     guide="none") +
  geom_line(data = plot.line, 
            aes(x = xvals, 
                y = yvals),
            size = 1, linetype = "dashed",
            na.rm = TRUE) +
  scale_x_continuous(limits = c(0, 0.5)) + 
  scale_y_continuous(limits = c(0, 0.7)) +
  labs(x    = "Proportion of time spent looking in the window",
       y    = "Proportion of trials pig helps",
       size = "Number of trials") +
  my_theme
```

```{r, plot-2, fig.height=8, fig.width=10, warning=FALSE}
plot
```

# How to cite R

"All analyses were performed using R Statistical Software (version 4.2.0; R Core Team 2022)".

Reference: R Core Team (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

```{r, cite-r}
citation()
version$version.string
```

```{r, cite-packages}
citation("tidyverse")
citation("viridis")
citation("glmmTMB")
citation("performance")
citation("DHARMa")
citation("fastDummies")
```

# Session Info

```{r, session}
sessionInfo()
```
