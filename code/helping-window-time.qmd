---
title: "Likelihood of helping and window time"
author: "Liza Moscovice, Anja Eggert and Jean-Loup Rault"
date: "`r Sys.Date()`" 
editor: visual
code-fold: false
toc: true
format: html
self-contained: true
---

# Libraries

```{r, libraries, warning=FALSE, message=FALSE, echo=TRUE}
library(tidyverse)     # tidy universe
library(viridis)       # color scale
library(glmmTMB)       # neg. binomial model
library(performance)   # testZeroInflation()
library(DHARMa)        # model diagnostics
library(fastDummies)   # dummy-coding
```

```{r, my_theme, echo = FALSE}
my_theme = theme_classic() +
  theme(axis.title = element_text(face="bold", size=14),
        axis.text  = element_text(size=12, angle = 0, vjust = 0.5),
        plot.title = element_text(face="bold", size=14),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

```{r, seed}
set.seed(1989)
```

# Data

Likelihood of helping of the potential helper and the attentiveness to trapped pigs.

# Read data

```{r, data}
dat <- read_csv("../data/helping-window-time.csv")
```

# Adjust data types

```{r}
dat <- dat %>% 
  mutate_at(vars(daily.test.order.within.group,
                 Test_subj.opens.emptybox.to20,
                 test.day), ~as.factor(.))
```

# Zero-inflated negative binomial model

The zero-inflation model describes the probability of observing an extra (i.e., structural) zero that is not generated by the conditional model.

## Run full model

```{r, model-contr}
contr = glmmTMBControl(optimizer = optim, optArgs = list(method="BFGS"))
```

```{r, model-full}
mod <- glmmTMB(Test_subj.opens.testbox ~
                 # fixed, continuous predictors
                 as.vector(scale(sqrt(train.rate.open.anybox)))+
                 as.vector(scale(Sep_rate.open.anybox))+
                 as.vector(scale(rate.look.testwindow.s.per.min))+
                 as.vector(scale(rate.look.emptywindow.s.per.min))+
                 # fixed, categorical predictors
                 Test_subj.opens.emptybox.to20       + 
                 test.day                            +
                 daily.test.order.within.group       +
                 related                             + 
                 # random effects
                 (1|uniq.group),
               # Negative binomial distribution
               family = "nbinom2",
               # expect zero-inflation equal in all obs
               ziformula = ~ 1,
               # data set
               data   = dat,
               # numerical optimizer
               control = contr)
```

## Run reduced model

```{r, model-reduced}
mod.red <- glmmTMB(Test_subj.opens.testbox ~
                 # fixed, continuous predictors
                 as.vector(scale(Sep_rate.open.anybox))+
                 as.vector(scale(rate.look.emptywindow.s.per.min))+
                 # fixed, categorical predictors
                 Test_subj.opens.emptybox.to20       + 
                 test.day                            +
                 daily.test.order.within.group       +
                 related                             + 
                 # random effects
                 (1|uniq.group),
               # Negative binomial distribution
               family = "nbinom2",
               # expect zero-inflation equal in all obs
               ziformula = ~ 1,
               # data set
               data   = dat,
               # numerical optimizer
               control = contr)
```

## Model comparison

-   Likelihood ratio test compares goodness of fit of of the reduced and the full model, *i.e.*, determine whether or not adding complexity (adding more parameters) makes the full model significantly more accurate

```{r, model-comp}
anova(mod.red, mod, test='Chisq')
```

## Summary of model

```{r, model-summary}
summary(mod)
```

```{r, model-table}
car::Anova(mod)
```

## Performance of model

-   `performance` package used to check model assumptions

```{r, perf-1}
performance::check_collinearity(mod)
```

```{r, perf-2}
performance::check_overdispersion(mod)
```

-   `DHARMa` package used to test for zero-inflation, which compares the distribution of expected zeros from simulations against the observed zeros

```{r, perf-3}
DHARMa::testZeroInflation(mod)
```

# Plot

-   fit an additional **plot.model** with all predictors except the predictor of interest having a mean of zero

## Dummy-coding

-   using `fastDummies` to dummy-code categorical predictors, continuous predictors are z-transformed

```{r, dummy-code}
dat.dum <- fastDummies::dummy_cols(dat,
                                   select_columns = c(
                                     "test.day", 
                                     "daily.test.order.within.group",
                                     "Test_subj.opens.emptybox.to20",
                                     "related"),
                                   remove_first_dummy = TRUE) %>% 
  # categorical, dummy predictors
  mutate_at(vars(starts_with("test.day_")),
            ~(.)-mean(.)) %>%
  mutate_at(vars(starts_with("daily.test.order.within.group_")),
            ~(.)-mean(.)) %>%
  mutate_at(vars(starts_with("Test_subj.opens.emptybox.to20_")), 
            ~(.)-mean(.)) %>%
  mutate_at(vars(starts_with("related_")),
            ~(.)-mean(.))
```

## Run plot model

```{r, plot-model}
plot.mod <- glmmTMB(Test_subj.opens.testbox ~
                      # fixed, continuous predictors
                      as.vector(scale(sqrt(train.rate.open.anybox)))+
                      as.vector(scale(Sep_rate.open.anybox))+
                      # no scaling and converted to proportion for figure
                      prop.look.test.window + 
                      as.vector(scale(rate.look.emptywindow.s.per.min))+
                      # dummy coded categorical predictors
                      test.day_2                            +
                      test.day_3                            +
                      test.day_4                            +
                      test.day_5                            +
                      daily.test.order.within.group_2       +
                      Test_subj.opens.emptybox.to20_1       + 
                      related_y                             + 
                       # random effects
                       (1|uniq.group),
                     # Negative binomial distribution
                     family = "nbinom2",
                     # expect zero-inflation equal in all obs
                     ziformula = ~ 1,
                     # data set
                     data   = dat.dum,
                     # numerical optimizer
                     control = contr)
```

## Extract fixed effects

-   create a vector spanning the range of `prop.look.test.window`
-   get fitted/estimated values for negative binomial part and zero-inflated part, with `fixef()`
-   as the fitted values are in the logit-link space, they need to be transformed into the space of the measurements

```{r, fixed-eff}
coeff.fixed <- fixef(plot.mod)
coeff.ci <- confint(plot.mod)

xvals <- seq(from       = min(dat.dum$prop.look.test.window),
             to         = max(dat.dum$prop.look.test.window),
             length.out = 100)

yvals.nb <- coeff.fixed$cond["(Intercept)"] +
  coeff.fixed$cond["prop.look.test.window"]*xvals

yvals.ci.l <- coeff.ci["cond.(Intercept)",1] +
   coeff.ci["cond.prop.look.test.window",1]*xvals

yvals.ci.h <- coeff.ci["cond.(Intercept)",2] +
   coeff.ci["cond.prop.look.test.window",2]*xvals

yvals.nb <- exp(yvals.nb)
yvals.ci.l <- exp(yvals.ci.l)
yvals.ci.h <- exp(yvals.ci.h)


yvals.zi <- coeff.fixed$zi["(Intercept)"]
yvals.zi <- exp(yvals.zi)/(1+exp(yvals.zi))

yvals <- (1-yvals.zi)*yvals.nb
yvals.l <- (1-yvals.zi)*yvals.ci.l
yvals.h <- (1-yvals.zi)*yvals.ci.h

plot.line <- tibble(xvals, yvals, yvals.l, yvals.h) %>% 
  filter(xvals <= 0.5)
```

## Plot it

-   group by `pot.helper.uniq.id` and calculate the mean of `prop.look.test.window` and `Test_subj.opens.testbox`

```{r, plot-1}
plot <- dat.dum %>% 
  group_by(pot.helper.uniq.id)%>%
  summarise(mean.look.min = mean(prop.look.test.window),
            mean.help     = mean(Test_subj.opens.testbox),
            n_trials      = n()) %>% 
  ungroup() %>% 
  mutate(uniq.group = str_sub(pot.helper.uniq.id,1,5)) %>% 
  
  ggplot() +
  geom_jitter(aes(x    = mean.look.min, 
                  y    = mean.help, 
                  col  = as.factor(uniq.group),
                  size = n_trials),
              alpha = 0.7,
              na.rm = TRUE) + 
  scale_size(range = c(3, 4)) +
  scale_color_manual(values = viridis(n=8),
                     guide="none") +
  geom_line(data = plot.line, 
            aes(x = xvals, 
                y = yvals),
            size = 1, linetype = "dashed",
            na.rm = TRUE) +
  # add confideence lines
  geom_line(data = plot.line,
            aes(x = xvals,
                y = yvals - yvals.l),
            size = 1, linetype = "dashed", col = "gray50",
            na.rm = TRUE) +
  geom_line(data = plot.line,
            aes(x = xvals,
                y = yvals + yvals.h),
            size = 1, linetype = "dashed", col = "gray50",
            na.rm = TRUE) +
  scale_x_continuous(limits = c(0, 0.5)) + 
  scale_y_continuous(limits = c(0, 0.7)) +
  labs(x    = "Proportion time looking at window of test compartment",
       y    = "Proportion of trials released trapped pig",
       size = "Number of trials") +
  my_theme
```

```{r, plot-2, fig.height=8, fig.width=10, warning=FALSE}
plot
```

# How to cite R

"All analyses were performed using R Statistical Software (version 4.2.0; R Core Team 2022)".

Reference: R Core Team (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

```{r, cite-r}
citation()
version$version.string
```

```{r, cite-packages}
citation("tidyverse")
citation("viridis")
citation("glmmTMB")
citation("performance")
citation("DHARMa")
citation("fastDummies")
```

# Session Info

```{r, session}
sessionInfo()
```
